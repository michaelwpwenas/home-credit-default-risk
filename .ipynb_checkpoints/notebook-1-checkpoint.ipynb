{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf86c5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data\n",
    "app_train = pd.read_csv('application_train.csv')\n",
    "app_test = pd.read_csv('application_test.csv')\n",
    "bureau = pd.read_csv('bureau.csv')\n",
    "bureau_balance = pd.read_csv('bureau_balance.csv')\n",
    "credit_card = pd.read_csv('credit_card_balance.csv')\n",
    "POS = pd.read_csv('POS_CASH_balance.csv')\n",
    "prev = pd.read_csv('previous_application.csv')\n",
    "payments = pd.read_csv('installments_payments.csv')\n",
    "\n",
    "# Data understanding\n",
    "print(\"Application train shape:\", app_train.shape)\n",
    "print(\"Application test shape:\", app_test.shape)\n",
    "print(\"Target distribution:\\n\", app_train['TARGET'].value_counts(normalize=True))\n",
    "\n",
    "# Data cleaning function\n",
    "def clean_data(df):\n",
    "    # Handle missing values\n",
    "    missing_percent = df.isnull().sum() / len(df) * 100\n",
    "    columns_to_drop = missing_percent[missing_percent > 60].index\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Separate numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Impute numerical missing values with median\n",
    "    num_imputer = SimpleImputer(strategy='median')\n",
    "    df[numerical_cols] = num_imputer.fit_transform(df[numerical_cols])\n",
    "    \n",
    "    # Impute categorical missing values with mode\n",
    "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Clean the main application data\n",
    "app_train_clean = clean_data(app_train)\n",
    "app_test_clean = clean_data(app_test)\n",
    "\n",
    "# Feature engineering for auxiliary data\n",
    "def aggregate_bureau_data(df):\n",
    "    # Aggregate bureau data\n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({\n",
    "        'SK_ID_BUREAU': 'count',\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': 'mean',\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': 'mean',\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_ENDDATE_FACT': ['min', 'max', 'mean'],\n",
    "        'AMT_ANNUITY': ['max', 'mean']\n",
    "    })\n",
    "    bureau_agg.columns = ['_'.join(col).upper() for col in bureau_agg.columns]\n",
    "    bureau_agg.reset_index(inplace=True)\n",
    "    \n",
    "    return bureau_agg\n",
    "\n",
    "# Aggregate all auxiliary data\n",
    "bureau_agg = aggregate_bureau_data(bureau)\n",
    "\n",
    "# Merge with main application data\n",
    "app_train_final = app_train_clean.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
    "app_test_final = app_test_clean.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
    "\n",
    "# Fill missing values from merged data\n",
    "app_train_final.fillna(0, inplace=True)\n",
    "app_test_final.fillna(0, inplace=True)\n",
    "\n",
    "# EDA and Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='TARGET', data=app_train_final)\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.savefig('target_distribution.png')\n",
    "\n",
    "# Correlation with target\n",
    "correlations = app_train_final.corr()['TARGET'].sort_values(ascending=False)\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlations.head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Features Correlated with Target')\n",
    "plt.savefig('feature_correlation.png')\n",
    "\n",
    "# Income vs Credit analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='AMT_INCOME_TOTAL', y='AMT_CREDIT', hue='TARGET', \n",
    "                data=app_train_final, alpha=0.5)\n",
    "plt.title('Income vs Credit Amount by Target')\n",
    "plt.savefig('income_vs_credit.png')\n",
    "\n",
    "# Save processed data\n",
    "app_train_final.to_csv('processed_train.csv', index=False)\n",
    "app_test_final.to_csv('processed_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
